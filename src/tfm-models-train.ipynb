{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Càrrega de llibreries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Llibreries requerides\nimport os\nimport time\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img, ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_in_prep\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Input, Dropout, Flatten, GlobalAveragePooling2D\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.utils.vis_utils import plot_model\nfrom tensorflow.keras.callbacks  import EarlyStopping, ModelCheckpoint, Callback\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Llibreria adicional pel disposar de models basats en arquitectures Squeeze-and-excitation\n!pip install git+https://github.com/qubvel/classification_models.git\n\nfrom classification_models.keras import Classifiers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Definició de constants"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tamany de la imatge a llegir\nIM_WIDTH = 224\nIM_HEIGHT = 224\nSIZE = (IM_WIDTH,IM_HEIGHT)\n#Etiquetes\nNUM_CLASSES = 3 # 0-negative, 1-neutral, 2-positive\nCLASSES_NAMES = ['Negatiu','Neutre','Positiu']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Directoris de treball\nTWITTER_DS_DIR = '/kaggle/input/twittertestdataset/'\nBT4SA_DS_DIR = '/kaggle/input/iteracio3/iteracio3/'\nWORK_DIR = '/kaggle/working/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## Definició de funcions"},{"metadata":{},"cell_type":"markdown","source":"### Generació dels models"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Funció build_ResNet50 que retorna el model base basat en ResNet50\ndef build_ResNet50(weights=None):\n    resnet_pretrained_model = ResNet50(include_top = False, #les capes fully-connected les afegirem segons la nostra necessitat\n                                       weights = weights, #Model ResNet50 pre-entrenat amb ImageNet o None\n                                       pooling = 'avg',\n                                       input_tensor=Input(shape=(IM_WIDTH, IM_HEIGHT,3)))\n    #Evitem entrenar les capes del model resnet50 pre-entrenat\n    for layer in resnet_pretrained_model.layers:\n        layer.trainable = False\n    return resnet_pretrained_model\n\ndef build_SEResNet50(weights=None):\n    \n    SEResNet50, seresnet50_in_prep = Classifiers.get('seresnet50')\n    seresnet_model = SEResNet50(input_shape=(IM_WIDTH,IM_HEIGHT,3), weights=weights, include_top=False)\n    \n    for layer in seresnet_model.layers:\n        layer.trainable = False\n   \n    return seresnet_model,seresnet50_in_prep\n\ndef create_model(pretrained_model, weights, add_pooling=False):\n    #creació del model final basat en un pre-entrenat\n    modelx = pretrained_model.output\n    if add_pooling == True:\n        modelx = GlobalAveragePooling2D()(modelx)\n    modelx = Dense(1024, activation='relu')(modelx)\n    modelx = Dropout(0.4)(modelx)\n    modelx = Dense(512, activation='relu')(modelx)\n    modelx = Dropout(0.4)(modelx)\n    output = Dense(NUM_CLASSES, activation='softmax')(modelx)\n    return_model = Model(inputs=pretrained_model.inputs, outputs=output)\n    #Càrrega dels pesos passats com a paràmetre\n    if weights != None:\n        return_model.load_weights(weights)\n    \n    return return_model\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Càrrega de dades"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_datagens(model_preprocessor, batch_size):\n\n    train_datagen = ImageDataGenerator(preprocessing_function=model_preprocessor)\n    val_datagen = ImageDataGenerator(preprocessing_function=model_preprocessor)\n\n    bt4sa_ds_train = BT4SA_DS_DIR + 'train/'\n    train_generator = train_datagen.flow_from_directory(\n      bt4sa_ds_train,\n      target_size=(IM_WIDTH, IM_HEIGHT),\n      batch_size=batch_size,\n      seed=42,\n      class_mode='categorical',  \n    )\n\n    bt4sa_ds_val = BT4SA_DS_DIR + 'val/'\n    val_generator = val_datagen.flow_from_directory(\n      bt4sa_ds_val,\n      target_size=(IM_WIDTH, IM_HEIGHT),\n      batch_size=batch_size,\n      seed=42,\n      class_mode='categorical',  \n    )\n    \n    return train_generator,val_generator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Callbacks"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Custom callback available in Kaggle\nclass TimerCallback(Callback):\n    \n    def __init__(self, maxExecutionTime, byBatch = False, on_interrupt=None):\n        \n# Arguments:\n#     maxExecutionTime (number): Time in minutes. The model will keep training \n#                                until shortly before this limit\n\n#     byBatch (boolean)     : If True, will try to interrupt training at the end of each batch\n#                             If False, will try to interrupt the model at the end of each epoch    \n#                            (use `byBatch = True` only if each epoch is going to take hours)          \n\n#     on_interrupt (method)          : called when training is interrupted\n#         signature: func(model,elapsedTime), where...\n#               model: the model being trained\n#               elapsedTime: the time passed since the beginning until interruption   \n\n        \n        self.maxExecutionTime = maxExecutionTime * 60\n        self.on_interrupt = on_interrupt\n        \n        #the same handler is used for checking each batch or each epoch\n        if byBatch == True:\n            #on_batch_end is called by keras every time a batch finishes\n            self.on_batch_end = self.on_end_handler\n        else:\n            #on_epoch_end is called by keras every time an epoch finishes\n            self.on_epoch_end = self.on_end_handler\n    \n    \n    #Keras will call this when training begins\n    def on_train_begin(self, logs):\n        self.startTime = time.time()\n        self.longestTime = 0            #time taken by the longest epoch or batch\n        self.lastTime = self.startTime  #time when the last trained epoch or batch was finished\n    \n    \n    #this is our custom handler that will be used in place of the keras methods:\n        #`on_batch_end(batch,logs)` or `on_epoch_end(epoch,logs)`\n    def on_end_handler(self, index, logs):\n        \n        currentTime      = time.time()                           \n        self.elapsedTime = currentTime - self.startTime    #total time taken until now\n        thisTime         = currentTime - self.lastTime     #time taken for the current epoch\n                                                               #or batch to finish\n        \n        self.lastTime = currentTime\n        \n        #verifications will be made based on the longest epoch or batch\n        if thisTime > self.longestTime:\n            self.longestTime = thisTime\n        \n        \n        #if the (assumed) time taken by the next epoch or batch is greater than the\n            #remaining time, stop training\n        remainingTime = self.maxExecutionTime - self.elapsedTime\n        if remainingTime < self.longestTime:\n            \n            self.model.stop_training = True  #this tells Keras to not continue training\n            print(\"\\n\\nTimerCallback: Finishing model training before it takes too much time. (Elapsed time: \" + str(self.elapsedTime/60.) + \" minutes )\\n\\n\")\n            \n            #if we have passed the `on_interrupt` callback, call it here\n            if self.on_interrupt is not None:\n                self.on_interrupt(self.model, self.elapsedTime)\n                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Generació dels callbacks necessaris per a l'entrenament del model\ndef generate_callbacks(model_CP_weights_file):\n    #Guardem els pesos del millor model entrenat monitoritzant la pèrdua sobre el conjunt de validació\n    checkpoint = ModelCheckpoint(model_CP_weights_file, monitor='val_loss', save_best_only=True)\n    #Aturem l'entrenament sino millora després de 10 èpoques\n    earlyStopping = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n    #La execució dels kernels de kaggle podem durar 9h com a màxim amb GPU (540min). Auturarem l'entrenament si dura més de 530min per precaució\n    timercallback = TimerCallback(530)    \n    \n    callbacks_list = [checkpoint, earlyStopping, timercallback]\n    \n    return callbacks_list\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Entrenament models"},{"metadata":{},"cell_type":"markdown","source":"#### Paràmetres globals"},{"metadata":{"trusted":true},"cell_type":"code","source":"#continue_training: True  - Carrega els pesos de la darrera sessió d'entrenament per a tot el model\n#                   False - Utilitza els pesos de imagenet en el model base per a l'extracció de característiques (pel 1r entrenament)\ncontinue_training = True\nmodel_to_train = 'ResNet50'  #ResNet50 o SEResNet50\nepochs = 100\nBATCH_SIZE = 32","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Paràmetres per al model basat en ResNet50"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Fitxers a crear\n#model_CP_callback_weights - Nom del fitxer a desar amb els pesos de l'entrenament generat pel callback CheckPoint (extensió .hdf5)\nresnet50_CP_callback_weights = 'resnet50_CP_weights_adamlr01_part2.hdf5'\n#model_fit_hist            - Nom del fitxer a desar amb l'historic de l'entrenament (extensió .npy)\nresnet50_fit_hist  = 'resnet50_fit_hist_adamlr01_part2.npy'\n\n## Fitxers a llegir\n# trained_model_resnet_cp_weights - pesos desats pel callback checkpoint en la darrera part de l'entrenament\ntrained_model_resnet_cp_weights = '/kaggle/input/tfm-models-train/resnet50_CP_weights_adamlr01_part1.hdf5'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Paràmetres per al model basat en SEResNet50"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Fitxers a crear\n#model_CP_callback_weights - Nom del fitxer a desar amb els pesos de l'entrenament generat pel callback CheckPoint (extensió .hdf5)\nseresnet50_CP_callback_weights = 'seresnet50_CP_weights_nadam_part1.hdf5'\n#model_fit_hist            - Nom del fitxer amb l'historic de l'entrenament (extensió .npy)\nseresnet50_fit_hist  = 'seresnet50_fit_hist_nadam_part1.npy'\n## Fitxers a llegir\n# trained_model_seresnet_cp_weights - pesos desats pel callback checkpoint en la darrera part de l'entrenament\ntrained_model_seresnet_cp_weights = '/kaggle/input/seresnetsdgpart1/seresnet50_CP_weights_nadam_part1.hdf5'\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Creació i compilació del model"},{"metadata":{"trusted":true},"cell_type":"code","source":"if model_to_train == 'ResNet50':\n    #1r entrenament o continuació\n    if continue_training == False:\n        base_weights = \"imagenet\"\n        model_weights = None\n    else:\n        base_weights = None\n        model_weights = trained_model_resnet_cp_weights\n        \n    #Fitxers que generarem en aquesta sessió d'entrenament\n    model_CP_callback_weights = resnet50_CP_callback_weights\n    model_fit_hist  = resnet50_fit_hist\n\n    #Creació del model base per extreure les característiques de les imatges basat en ResNet50\n    add_pooling_layer = False\n    modelx = build_ResNet50(base_weights)\n    model_preprocessor = resnet50_in_prep  \n    \nelif model_to_train == 'SEResNet50':\n    #1r entrenament o continuació\n    if continue_training == False:\n        base_weights = \"imagenet\"\n        model_weights = None\n    else:\n        base_weights = None\n        model_weights = trained_model_seresnet_cp_weights\n        \n    #Fitxers que generarem en aquesta sessió d'entrenament    \n    model_CP_callback_weights = seresnet50_CP_callback_weights\n    model_fit_hist  = seresnet50_fit_hist\n    \n    #Creació del model base per extreuure les característiques de les imatges basat en SEResNet50 (la funció també retorna el seu preprocessor associat)\n    add_pooling_layer = True\n    modelx,model_preprocessor = build_SEResNet50(base_weights)\n            \nelse:\n    print(\"\\n\\nEl model especificat en la variable model_to_train no és vàlid (valors permesos: ResNet50 o SEResNet50)\")        \n        \n#Creació del model complet: base + capes pròpies \n\n\n#optimizer = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\noptimizer = tf.keras.optimizers.Adam(lr=0.01)\n#optimizer = tf.keras.optimizers.Nadam()\n\n\nmodel = create_model(modelx, model_weights, add_pooling_layer)\nmodel.compile(optimizer= optimizer, loss='categorical_crossentropy', metrics=['accuracy'])    \n    \nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Càrrega de dades"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator,val_generator = create_datagens(model_preprocessor, BATCH_SIZE)\n\nSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=val_generator.n//val_generator.batch_size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Entrenament"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Callbacks\ncallback_list = generate_callbacks(model_CP_callback_weights)\n\n#Entrenament del model\nmodel_fit = model.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n                      validation_data=val_generator, validation_steps=STEP_SIZE_VALID,\n                      epochs=epochs, callbacks=callback_list)                      \n                      \nnp.save(model_fit_hist, model_fit.history)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}